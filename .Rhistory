setwd("~/[1] R directory/data")
setwd("~/[1] R directory/data")
setwd("~/[1] R directory/data")
setwd("~/[1] R directory/data")
setwd("~/[1] R directory/data")
setwd("~/[1] R directory")
activity <- read.csv("activity.csv", header = TRUE, stringsAsFactors = FALSE)
install.packages("dplyr")
install.packages("R.utils")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
install.packages(rattle)
set.seed(125)
# 1. Subset the data to a training set and testing set based on the Case variable in the data set.
inTrain <- createDataPartition(y = segmentationOriginal$Case, list = FALSE)
train <- subset(segmentationOriginal, Case == "Train")
test <- subset(segmentationOriginal, Case == "Test")
# 2. Set the seed to 125 and fit a CART model with the rpart method using all
# predictor variables and default caret settings.
modFit <- train(Class ~ ., data = train, method = "rpart")
modFit$finalModel
# 3. In the final model what would be the final model prediction for cases with the following variable values:
# Look at the output
# a. TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2       PS
# b. TotalIntench2 = 50,000; FiberWidthCh1 = 10;VarIntenCh4 = 100       WS
# c. TotalIntench2 = 57,000; FiberWidthCh1 = 8;VarIntenCh4 = 100        PS
# d. FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2              Not possible to predict
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
install.packages(AppliedPredictiveModeling)
AppliedPredictiveModeling
library(rattle)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
install.package(caret)
install.packages(caret)
install.packages("caret")
install.packages("rpart")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("RcolorBrewer")
yes
instal.packages("RColorBrewer")
install.packages("RColorBrewer")
install.packages("rattle")
install.packages("randomForest")
library(caret)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)
training <- read.csv(pml-training), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(pml-testing), na.strings=c("NA","#DIV/0!",""))
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)
training <- read.csv(pml-training), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(pml-testing), na.strings=c("NA","#DIV/0!",""))
training <- read.csv(pml-training), na.strings=c("NA","#DIV/0!","")
testing <- read.csv(pml-testing), na.strings=c("NA","#DIV/0!","")
testing <- read.csv(pml-testing)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)
training <- read.csv(file="pml-training.csv"), na.strings=c("NA","#DIV/0!","")
testing <- read.csv(file="pml-testing.csv"), na.strings=c("NA","#DIV/0!","")
testing <- read.csv(file="pml-testing.csv"), na.strings=c("NA","#DIV/0!")
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)
training <- read.csv(file="pml-training.csv"), na.strings=c("NA","#DIV/0!")
testing <- read.csv(file="pml-testing.csv"), na.strings=c("NA","#DIV/0!")
testing <- read.csv(file="pml-testing.csv"), na.strings=c("NA","#DIV/0!",""))
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(12345)
training <- read.csv((file="pml-training.csv"), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv((file="pml-testing.csv"), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
myDataNZV <- nearZeroVar(myTraining, saveMetrics=TRUE)
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
"kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
"max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
"var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
"stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
"kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
"max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
"kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
"skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
"amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
"skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
"max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
"amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
"avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
"stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!myNZVvars]
#To check the new N?? of observations
dim(myTraining)
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { #if n?? NAs > 60% of total observations
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
trainingV3 <- trainingV3[ , -j] #Remove that column
}
}
}
}
#To check the new N?? of observations
dim(trainingV3)
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) #already with classe column removed
myTesting <- myTesting[clean1]
testing <- testing[clean2]
#To check the new N?? of observations
dim(myTesting)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)
install.packages("e1071")
confusionMatrix(predictionsA1, myTesting$classe)
modFitB1 <- randomForest(classe ~. , data=myTraining)
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionsB1, myTesting$classe)
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionsB1, myTesting$classe)
confusionMatrix(predictionsB1, myTesting$classe)
modFitB1 <- randomForest(classe ~. , data=myTraining)
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionsB1, myTesting$classe)
modFitB1 <- randomForest(classe ~. , data=myTraining)
>
>modFitB1 <- randomForest(classe ~. , data=myTraining)
predictionsB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionsB1, myTesting$classe)
>predictionsB1 <- predict(modFitB1, myTesting, type = "class")
>confusionMatrix(predictionsB1, myTesting$classe)
predictionsB2 <- predict(modFitB1, testing, type = "class")
modFitB1 <- randomForest(classe ~. , data=myTraining)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
set.seed(12345)
training <- read.csv((file="pml-training.csv"), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv((file="pml-testing.csv"), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
dim(myTesting)
dim(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 4)))
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
plot(modFitB1)
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
set.seed(12345)
fitControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1)
gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
trControl = fitControl,
verbose = FALSE)
remove.packages("plyr")
install.packages("plyr")
library("plyr")
library(caret)
# pml_write_files(predictionB2)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
set.seed(12345)
training <- read.csv((file="pml-training.csv"), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv((file="pml-testing.csv"), na.strings=c("NA","#DIV/0!",""))
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]
nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
myTraining <- myTraining[c(-1)]
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
for(j in 1:length(trainingV3)) {
if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
trainingV3 <- trainingV3[ , -j]
}
}
}
}
# Set back to the original variable name
myTraining <- trainingV3
rm(trainingV3)
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58])  # remove the classe column
myTesting <- myTesting[clean1]         # allow only variables in myTesting that are also in myTraining
testing <- testing[clean2]             # allow only variables in testing that are also in myTraining
dim(myTesting)
dim(testing)
for (i in 1:length(testing) ) {
for(j in 1:length(myTraining)) {
if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
class(testing[j]) <- class(myTraining[i])
}
}
}
# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
set.seed(12345)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsA1, myTesting$classe)
cmtree
plot(cmtree$table, col = cmtree$byClass, main = paste("Decision Tree Confusion Matrix: Accuracy =", round(cmtree$overall['Accuracy'], 4)))
set.seed(12345)
modFitB1 <- randomForest(classe ~ ., data=myTraining)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
cmrf <- confusionMatrix(predictionB1, myTesting$classe)
cmrf
plot(modFitB1)
plot(cmrf$table, col = cmtree$byClass, main = paste("Random Forest Confusion Matrix: Accuracy =", round(cmrf$overall['Accuracy'], 4)))
set.seed(12345)
fitControl <- trainControl(method = "repeatedcv",
number = 5,
repeats = 1)
gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbmFinMod1 <- gbmFit1$finalModel
gbmPredTest <- predict(gbmFit1, newdata=myTesting)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, myTesting$classe)
gbmAccuracyTest
plot(gbmFit1, ylim=c(0.9, 1))
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
# Write the results to a text file for submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
# pml_write_files(predictionB2)
gbmFinMod1 <- gbmFit1$finalModel
gbmPredTest <- predict(gbmFit1, newdata=myTesting)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, myTesting$classe)
gbmAccuracyTest
plot(gbmFit1, ylim=c(0.9, 1))
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
# Write the results to a text file for submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
# pml_write_files(predictionB2)
gbmFit1 <- train(classe ~ ., data=myTraining, method = "gbm",
trControl = fitControl,
verbose = FALSE)
gbmFinMod1 <- gbmFit1$finalModel
gbmPredTest <- predict(gbmFit1, newdata=myTesting)
gbmAccuracyTest <- confusionMatrix(gbmPredTest, myTesting$classe)
gbmAccuracyTest
plot(gbmFit1, ylim=c(0.9, 1))
predictionB2 <- predict(modFitB1, testing, type = "class")
predictionB2
# Write the results to a text file for submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
# pml_write_files(predictionB2)
dim(myTesting)
```
install.packages('devtools')
install.packages('devtools')
install.packages("devtools")
sudo apt-get install libxml2-dev
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
install.packages("(AppliedPredictiveModeling")
install.packages((AppliedPredictiveModeling)
install.packages("(AppliedPredictiveModeling")
install.packages('maniplulate')
> install.packages('manipulate')
install.packages("manipulate")
install.packages("rcharts")
install.packages("rCharts")
library("devtools")
library("plotly")
library_github("ropensci/plotly")
install_github("ropensci/plotly")
plotly:::verify("AndreasEconomides")
plotly:::verify("efzn5fgji3")
Sys.setenv("plotly_username"="AndreasEconomides")
Sys.setenv("plotly_api_key"="efzn5fgji3")
plotly:::verify("AndreasEconomides")
plotly:::verify("efzn5fgji3")
plotly:::verify("plotly:::verify("efzn5fgji3"")
plotly:::verify("AndreasEconomides")
Sys.setenv("plotly_username"="AndreasEconomides")
plotly:::verify("AndreasEconomides")
library("plotly")
plotly:::verify("AndreasEconomides")
Sys.setenv("plotly_username"="AndreasEconomides")
plotly:::verify("AndreasEconomides")
install.packages("plotly")
install.packages("plotly")
plotly:::verify("AndreasEconomides")
Sys.setenv("plotly_username"="AndreasEconomides")
plotly:::verify("AndreasEconomides")
library("devtools")
install_github("slidify","ramnathv")
library("curl")
install.packages("curl")
install_github("slidify", "ramnathv")
install_gitub("slidifylibraries", "ramnathv")
install_github("slidifylibraries", "ramnathv")
library("slidify")
setwd("~/Data Science/9 - Developing Data Products/Course Project/presentation")
install.packages("slidify")
install_github("slidify", "ramnathv"
)
install_github("slidify", "ramnathv")]
install.packages("devtools")
install_github("slidify", "ramnathv")
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library("slidift")
library("slidify")
author("The_Map_of_Happiness")
